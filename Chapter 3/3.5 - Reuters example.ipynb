{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters Dataset\n",
    "In this example, we are attempting to classify Reuters newswires into 46 mutually exclusive classes using a densely connected neural network.\n",
    "\n",
    "This is a case of *single-label, multiclass classification*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels),(test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will skip the step of reversing the encoding for this example. I'm not particularly interested in what this newswire translates to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "The input data will be treated the same for both train and test sets. The label data will be handled differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to encode the labels using a one-hot encoding vector.  \n",
    "Note: There are 46 possible labels.\n",
    "\n",
    "First, we will do this manually as a demonstration, but we can also use Keras' built in method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels),dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the built-in method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "In the previous example, we used 16-dimensional intermediate layers, but a 16-dimensional space may be too limited to learn to separate 46 different classes: such small layers may act as information bottlenecks, permanently dropping relevant information.\n",
    "\n",
    "For this reason, we'll use larger layers. Let's go with 64 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output will be a 46-dimensional vector. Each entry in this vector will represent a different output class. Additionally, the output uses a softmax activation. It means the network will output a *probability distribution* over the 46 different output classes, where `output[i]` is the probability that the sample belongs to class `i`. The 46 scores will sum to 1.\n",
    "\n",
    "The best loss function to use int his case is the `categorical_crossentropy`. It measures the distance between two probability distributions: here, between the probability distribution **output by the network** and the **true distribution of the labels**. By minimizing the distance between these two distributions, you train the network output something as close as posible to the true labels.\n",
    "\n",
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating your approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000] # Set aside first 10,000 samples for validation\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 3.1604 - accuracy: 0.4161 - val_loss: 1.7519 - val_accuracy: 0.6240\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.5276 - accuracy: 0.6776 - val_loss: 1.3025 - val_accuracy: 0.7200\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.1083 - accuracy: 0.7693 - val_loss: 1.1270 - val_accuracy: 0.7620\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.8430 - accuracy: 0.8289 - val_loss: 1.0397 - val_accuracy: 0.7810\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6730 - accuracy: 0.8654 - val_loss: 0.9748 - val_accuracy: 0.7900\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5411 - accuracy: 0.8897 - val_loss: 0.9406 - val_accuracy: 0.8100\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4351 - accuracy: 0.9158 - val_loss: 0.9061 - val_accuracy: 0.8190\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3591 - accuracy: 0.9239 - val_loss: 0.9326 - val_accuracy: 0.8030\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2932 - accuracy: 0.9391 - val_loss: 0.9240 - val_accuracy: 0.8060\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2470 - accuracy: 0.9450 - val_loss: 0.9319 - val_accuracy: 0.8150\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2014 - accuracy: 0.9521 - val_loss: 0.9411 - val_accuracy: 0.8130\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1870 - accuracy: 0.9533 - val_loss: 0.9438 - val_accuracy: 0.8220\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1651 - accuracy: 0.9546 - val_loss: 0.9755 - val_accuracy: 0.8210\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1499 - accuracy: 0.9578 - val_loss: 0.9865 - val_accuracy: 0.8120\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1351 - accuracy: 0.9561 - val_loss: 1.1698 - val_accuracy: 0.7780\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1347 - accuracy: 0.9578 - val_loss: 1.0064 - val_accuracy: 0.8150\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1131 - accuracy: 0.9653 - val_loss: 1.0694 - val_accuracy: 0.8010\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1143 - accuracy: 0.9601 - val_loss: 1.0758 - val_accuracy: 0.8200\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1065 - accuracy: 0.9611 - val_loss: 1.1060 - val_accuracy: 0.8090\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0988 - accuracy: 0.9640 - val_loss: 1.1981 - val_accuracy: 0.7860\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'k', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'k', label='Validation acc')\n",
    "\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the network begins to overfit after nine epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "16/16 [==============================] - 1s 26ms/step - loss: 3.0341 - accuracy: 0.3914 - val_loss: 1.7134 - val_accuracy: 0.6360\n",
      "Epoch 2/9\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.4798 - accuracy: 0.6962 - val_loss: 1.2994 - val_accuracy: 0.7110\n",
      "Epoch 3/9\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.0838 - accuracy: 0.7708 - val_loss: 1.1444 - val_accuracy: 0.7610\n",
      "Epoch 4/9\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.8454 - accuracy: 0.8193 - val_loss: 1.0391 - val_accuracy: 0.7830\n",
      "Epoch 5/9\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6747 - accuracy: 0.8607 - val_loss: 0.9653 - val_accuracy: 0.7980\n",
      "Epoch 6/9\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5299 - accuracy: 0.8931 - val_loss: 0.9480 - val_accuracy: 0.7980\n",
      "Epoch 7/9\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4376 - accuracy: 0.9127 - val_loss: 0.8996 - val_accuracy: 0.8180\n",
      "Epoch 8/9\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3414 - accuracy: 0.9305 - val_loss: 0.8746 - val_accuracy: 0.8230\n",
      "Epoch 9/9\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2749 - accuracy: 0.9431 - val_loss: 0.8768 - val_accuracy: 0.8220\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.9680 - accuracy: 0.7885\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=9,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9679708480834961, 0.7885128855705261]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this network is almost 80%. This is significant, considering that selecting a classifier at random would to about 19% accuracy.  \n",
    "We can demonstrate this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.182546749777382"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "\n",
    "np.random.shuffle(test_labels_copy)\n",
    "\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "\n",
    "float(np.sum(hits_array)) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Let's generate topic predictons for all of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the resulting vector is of length 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0]) # This will display the value with the highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way to handle labels and loss\n",
    "In the previous example, it was mentioned that another wayt to ecode the labels would be to cast them as an integer tensor. We can do this as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing this approach would change is the choice of the loss function. The loss function used above, `categorical_corssentropy`, expects the labels to follow a categorical encoding. Fortunately they already do in this dataset, as each integer represents some category.\n",
    "\n",
    "With integer labels, you should compile your model using `sparse_categorical_crossentropy` for the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The importance of having sufficiently large intermediate layers\n",
    "We mentioned earlier that because the final outputs are 46-dimensional, you should avoid intermediate layers with many fewer than 46 hidden units. Let's see what happens when you introduce an information bottleneck by having intermediate layers that are significantly less than 46-dimensional: for example, 4-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 3.6349 - accuracy: 0.0278 - val_loss: 3.1720 - val_accuracy: 0.1990\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.9468 - accuracy: 0.2583 - val_loss: 2.4741 - val_accuracy: 0.3030\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.1618 - accuracy: 0.3360 - val_loss: 1.7666 - val_accuracy: 0.6110\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4736 - accuracy: 0.6439 - val_loss: 1.4938 - val_accuracy: 0.6430\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1985 - accuracy: 0.6855 - val_loss: 1.4584 - val_accuracy: 0.6640\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1245 - accuracy: 0.7090 - val_loss: 1.4823 - val_accuracy: 0.6730\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.0361 - accuracy: 0.7288 - val_loss: 1.4455 - val_accuracy: 0.6680\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9402 - accuracy: 0.7529 - val_loss: 1.4551 - val_accuracy: 0.6750\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.9126 - accuracy: 0.7606 - val_loss: 1.5166 - val_accuracy: 0.6780\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8799 - accuracy: 0.7567 - val_loss: 1.5625 - val_accuracy: 0.6730\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8087 - accuracy: 0.7756 - val_loss: 1.5611 - val_accuracy: 0.6820\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.7809 - accuracy: 0.7868 - val_loss: 1.6155 - val_accuracy: 0.6780\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7615 - accuracy: 0.7912 - val_loss: 1.6890 - val_accuracy: 0.6680\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7188 - accuracy: 0.7967 - val_loss: 1.7531 - val_accuracy: 0.6740\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.7012 - accuracy: 0.7959 - val_loss: 1.7723 - val_accuracy: 0.6710\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6733 - accuracy: 0.8031 - val_loss: 1.8805 - val_accuracy: 0.6620\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6615 - accuracy: 0.8072 - val_loss: 1.9830 - val_accuracy: 0.6720\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.6195 - accuracy: 0.8183 - val_loss: 2.0128 - val_accuracy: 0.6630\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6181 - accuracy: 0.8105 - val_loss: 2.0781 - val_accuracy: 0.6670\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6047 - accuracy: 0.8212 - val_loss: 2.2316 - val_accuracy: 0.6640\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2.3818 - accuracy: 0.6630\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy has now dropped to about 65% from 79% in our model with 64-64-46 hidden units.\n",
    "\n",
    "This drop is mostly due to the fact that you're trying to compress a lot of information (enough information to recover the separation hyperplanes of 46 classes) into an intermediate space that is too low-dimensional. **The network is able to cram *most* of the necessary information into these four-dimensional representations, but not all of it.**\n",
    "\n",
    "Generally, you won't use more than 2 hidden layers. The input layer should have one hidden unit for each feature of the data, and the hidden layer should have the mean between the input layer and the output layer. This should give a good compromise between overfitting and compression for most cases. Let's do that now, and start by looking at the dimensionality of the input vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.7178 - accuracy: 0.4980 - val_loss: 1.4673 - val_accuracy: 0.6720\n",
      "Epoch 2/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3032 - accuracy: 0.7153 - val_loss: 1.2199 - val_accuracy: 0.7200\n",
      "Epoch 3/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9880 - accuracy: 0.7803 - val_loss: 1.0739 - val_accuracy: 0.7620\n",
      "Epoch 4/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7359 - accuracy: 0.8417 - val_loss: 0.9732 - val_accuracy: 0.7890\n",
      "Epoch 5/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.8794 - val_loss: 0.9306 - val_accuracy: 0.8000\n",
      "Epoch 6/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.9109 - val_loss: 0.9198 - val_accuracy: 0.8080\n",
      "Epoch 7/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.9195 - val_loss: 0.9585 - val_accuracy: 0.8030\n",
      "Epoch 8/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2693 - accuracy: 0.9407 - val_loss: 0.9509 - val_accuracy: 0.8060\n",
      "Epoch 9/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2214 - accuracy: 0.9459 - val_loss: 0.9840 - val_accuracy: 0.8070\n",
      "Epoch 10/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.9552 - val_loss: 0.9847 - val_accuracy: 0.8120\n",
      "Epoch 11/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1681 - accuracy: 0.9537 - val_loss: 1.0049 - val_accuracy: 0.8050\n",
      "Epoch 12/12\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1373 - accuracy: 0.9620 - val_loss: 1.0586 - val_accuracy: 0.8000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 1.2358 - accuracy: 0.7765\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(31, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(39, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=12,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting accuracy drop is only about 1%, which is much better than the network with hidden units 64-4-46, but it should be noted that there is still a drop from the network 64-64-46. This is because the output is of higher dimension than the number of features in this particular dataset. So it may be better in these situations to construct neural networks where the intermediate layers are of the same dimension as the output, for example 46-46-46:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.6941 - accuracy: 0.4388 - val_loss: 1.3665 - val_accuracy: 0.6970\n",
      "Epoch 2/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1565 - accuracy: 0.7422 - val_loss: 1.0778 - val_accuracy: 0.7680\n",
      "Epoch 3/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8197 - accuracy: 0.8215 - val_loss: 0.9774 - val_accuracy: 0.7940\n",
      "Epoch 4/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5681 - accuracy: 0.8760 - val_loss: 0.9255 - val_accuracy: 0.8000\n",
      "Epoch 5/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.9093 - val_loss: 0.9126 - val_accuracy: 0.8090\n",
      "Epoch 6/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3186 - accuracy: 0.9300 - val_loss: 0.9270 - val_accuracy: 0.8000\n",
      "Epoch 7/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2293 - accuracy: 0.9479 - val_loss: 0.9362 - val_accuracy: 0.8060\n",
      "Epoch 8/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2047 - accuracy: 0.9508 - val_loss: 0.9492 - val_accuracy: 0.8100\n",
      "Epoch 9/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1654 - accuracy: 0.9587 - val_loss: 1.0213 - val_accuracy: 0.8000\n",
      "Epoch 10/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1403 - accuracy: 0.9576 - val_loss: 1.0346 - val_accuracy: 0.8050\n",
      "Epoch 11/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.9595 - val_loss: 1.0698 - val_accuracy: 0.8050\n",
      "Epoch 12/12\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 0.9610 - val_loss: 1.1061 - val_accuracy: 0.8040\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 1.2401 - accuracy: 0.7881\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(46, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(46, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=12,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
